## Project: biosigner
## Details: Helper functions to build models on dataLs subsets generated by bootstraping
##          Computes the accuracy of the models, and the rank of the features
## Authors: Philippe Rinaudo and Etienne Thevenot (CEA)


## INPUT:  predTestFc: a factor of prediction
##         yTestFc: a factor of responses
## OUTPUT: accuracyN: accuracy of the prediction:
##                      for regression: R square (not used)
##                      for classification: balanced accuracy
getAccuracyF <- function(predTestFc = NULL,
                         yTestFc = NULL){

    if(class(yTestFc) != "numeric"){

      yTestVc <- as.character(yTestFc)
      yClassVc <- unique(yTestVc)
      if(length(yClassVc) != 2)
        stop("Computing accuracy for 2-class discrimination only")

      if(class(predTestFc) == "numeric")
        stop("Predicted output is numeric and original output is not numeric (factor or character)")
      predTestVc <- as.character(predTestFc)

      accuracyN <- 0
      for(yClassC in yClassVc){
        yClassVi <- which(yTestVc == yClassC)
        accuracyN <- accuracyN + (sum(predTestVc[yClassVi] == yTestVc[yClassVi]) / length(yClassVi))
      }
      accuracyN <- accuracyN / length(yClassVc)
      return(accuracyN)
    }
    ## else{ ## not used currently (for future regression applications)
    ##     SSE <- sum( (yTestFc - predTestFc)^2 )
    ##     SST <- sum( (yTestFc - mean(yTestFc))^2 )
    ##     accuracyN <- 1 - SSE/SST
    ##     return(accuracyN)
    ## }

} ## getAccuracyF


## SPECIFICATIONS: generates a list of models from bootstrap,
##                 see getModelAccuRankF for more details
## INPUT: dataLs: data and metadata,
##        respC: the response name (column of the sampleMetadata)
##        bootI: number of bootstraps
##        see getModelAccuRankF for the other arguments
## OUTPUT: a list of bootI models with accuracy and variable ranking
getBootModelF <- function(dataLs = NULL,
                          respC = NULL,
                          methC = NULL,
                          methNamLs = list(x = "x", y = "y"),
                          methArgLs = NULL,
                          predNamLs = list(object = "object", newdata = "newdata"),
                          predArgLs = NULL,
                          bootI = 0,
                          fixRankL = FALSE){

  ## generate the all the modelAccuRank generated by bootstrap
  modelAccuRankLs <- list()

  if(bootI != 0){

    for(i in 1:bootI){

      # generate the bootstrap
      dataLs <- bootExtractF(dataLs,
                             bootSubSampL = TRUE,
                             respC = respC)

      # generate the corresponding modelAccuRank
      modelAccuRank <- getModelAccuRankF(getBootTrainxF(dataLs),
                                         getBootTrainyF(dataLs, respC),
                                         methC = methC,
                                         methNamLs = methNamLs,
                                         methArgLs = methArgLs,
                                         xTestMN = getBootTestxF(dataLs),
                                         yTestFc = getBootTestyF(dataLs, respC),
                                         predNamLs = predNamLs,
                                         predArgLs = predArgLs)

      modelAccuRank$ind.test <- getBootTestIndF(dataLs)
      ## add to the heap
      modelAccuRankLs <- c(modelAccuRankLs, list(modelAccuRank))
    }
  }

  ## generate general evaluation, score...
  summaryLs <- getBootSummaryF(modelAccuRankLs)
  if(fixRankL){
      fixed.model <- getModelF(dataLs$dataMatrix,
                               dataLs$sampleMetadata$respC,
                               methC = methC,
                               methNamLs = methNamLs,
                               methArgLs = methArgLs)
      summaryLs$rankVn <- getImportanceF(fixed.model,
                                         dataLs$dataMatrix)
                                         ## dataLs$dataMatrix,
                                         ## dataLs$sampleMetadata$respC,
                                         ## summaryLs$accuracyN,
                                         ## predNamLs,
                                         ## predArgLs)
  }

  bootModelLs <- list(dataLs = dataLs,
                      modelAccuRankLs = modelAccuRankLs,
                      rankVn = summaryLs$rankVn,
                      accuracyN = summaryLs$accuracyN,
                      varImpVn = summaryLs$varImpVn,
                      varNamVc = summaryLs$varNamVc)

  return(bootModelLs)

} ## getBootModelF


## SPECIFICATIONS: generates the mean accuracy, median importance
##                 and corresponding rank from a list of modelAccuRank
##                 (generated from a same dataLs)
## INPUT: bootModelLs: a list of models with accuracy and variable rankings,
##                 generated by bootstrap (getBootModelF)
## OUTPUT: a list containing the mean evaluation, importance
##         and corresponding rank and feature names
getBootSummaryF <- function(bootModelLs = NULL){

    bootI <- length(bootModelLs)
    ## get the cumulative evaluation and scores evaluation
    accuCumN <- 0
    varI <- length(bootModelLs[[1]]$varImpVn)
    varImpMN <- matrix(nrow = bootI, ncol = varI)

    for(i in 1:bootI){
        accuCumN <- accuCumN + bootModelLs[[i]]$accuracyN
        varImpMN[i, ] <- rank(-bootModelLs[[i]]$varImpVn)
    }
    accuracyN <- accuCumN / bootI
    varImpVn <- apply(varImpMN, 2, median)
    rankVn <- rank(varImpVn, ties.method="max")

    return(list(rankVn = rankVn,
                accuracyN = accuracyN,
                varImpVn = varImpVn,
                varNamVc = bootModelLs[[1]]$varNamVc))
}


## INPUT: model: object containing a model
##        xTrainMN: the training set on which the model has been trained
##        xTestMN: a matrix of numerics (row: observations, column: features), used to test the model
##        yTestFc: response to predict with xTestMN as data
##        accuracyN: evaluation of the model generated with xTestMN and yTestFc
##        predNamLs: list of arguments names for the input model and the input newdata of responses of the prediction method (object, newdata by default)
##        predArgLs: a list of arguments for the prediction "methC" (except model and newdata)
## OUTPUT: numerical vector of feature importance
getImportanceF <- function(model = NULL,
                           xTrainMN = NULL
                           ## xTestMN = NULL,
                           ## yTestFc = NULL,
                           ## accuracyN = NULL,
                           ## predNamLs = list(object = "object",
                           ##     newdata = "newdata"),
                           ## predArgLs=NULL
                           ){

    if(class(model) == "svm"){ ## weights (w)

        varImpVn <- (t(model[["coefs"]]) %*% xTrainMN[model[["index"]],])^2

    }
    else if(class(model) == "opls"){ ## VIP

        ## initialize
        varImpVn <- rep(0, ncol(xTrainMN))
        ## get the variable with a VIP:
        vipVn <- getVipVn(model)
        vipVi <- which(colnames(xTrainMN) %in% names(vipVn))
        varImpVn[vipVi] <- vipVn

    }
    else if(class(model) == "randomForest"){

        varImpVn <- model[["importance"]][, 1]

    }
    ## else{ ## not currently used
    ##     ## generic metric to measure variable importance
    ##     ## TODO: generalize this given a score criteria in input (make a function), for example make a variable importance function
        ## varImpVn <- numeric(ncol(xTrainMN))
        ## for(j in 1:length(varImpVn)){
        ##     xTestMN.perm <- xTestMN
        ##     xTestMN.perm[, j] <- sample(xTestMN[, j])
        ##     predTestFc.perm <- getPredictionF(model,
        ##                                       xTestMN.perm,
        ##                                       predNamLs,
        ##                                       predArgLs)
        ##     varImpVn[j] <- accuracyN - getAccuracyF(predTestFc.perm,
        ##                                             yTestFc)
        ## }
    ## }
    names(varImpVn) <- colnames(xTrainMN)

    return(varImpVn)

} ## getImportanceF


## INPUT: xMN: a numerical matrix of predictors (row: observations, column: features),
##             used to train the model
##        yFc: a response factor (number of responses must match the number of
##             observations/row of xMN), used to train the model
##        methC: name of the classifier, i.e. an R function, with at least 2 inputs:
##               a numerical matrix and a response factor
##        methNamLs: arguments name for the input matrix and the input factor of
##                   responses of the method (x, y by default)
##        methArgLs: a list of arguments for the 'methC' R classifier
getModelF <- function(xMN = NULL,
                      yFc = NULL,
                      methC = NULL,
                      methNamLs = list(x = "x", y = "y"),
                      methArgLs = NULL){
    ## generating the full arguments for the model training
    ## generating the names of the args (to match the x and y)
    argNamFulVc <- c(methNamLs[["x"]],
                     methNamLs[["y"]],
                     names(methArgLs))

    ## generating the args list with the arg names just created
    argFulLs <- c(list(xMN, yFc), methArgLs)
    names(argFulLs) <- argNamFulVc
    ## generates the model from training set
    if(methC == "opls") {
        model <- try(do.call(methC, argFulLs), silent = TRUE)
        if(inherits(model, "try-error") &&
           substr(unclass(attr(model, "condition"))$message, 1, 85) == "No model was built because the first predictive component was already not significant") {
            argFulLs <- c(argFulLs, list(predI = 1))
            model <- do.call(methC, argFulLs)
        }
    } else
        model <- do.call(methC, argFulLs)

    return(model)
}


## SPECIFICATIONS: trains a model from a training data set and a training method (with args)
##                 then tests the model on a test set and compute the accuracy
##                 then evaluates the feature importance by feature permutation
## INPUT: xMN: a matrix of numerics (row: observations, column: features),
##             used to train the model
##        yFc: a response factor (number of responses must match the number of
##             observations/row of xMN), used to train the model
##        methC: a R function, with at least 2 inputs: a numercial matrix and a
##               vector of responses
##        methNamLs: list of arguments names for the input matrix and the input
##                   vector of responses of the method (x,y by default)
##        methArgLs: a list of arguments for the R function "methC" (except data and
##                   response)
##        xTestMN: a matrix of numerics (row: observations, column: features),
##                 used to test the model
##        yTestFc: a vector of responses (number of responses must match the number
##                 of observations/row of xTestMN), used to test the model
##        predNamLs: list of arguments names for the input model and the input newdata
##                   of responses of the prediction method (object,newdata by default)
##        predArgLs: a list of arguments for the prediction "methC"
##                   (except model and newdata)
##        TODO: add an argument to choose how to evaluate the model
##              (currently accuracy only)
## OUTPUT: a list containing the rank of the features, their importance,
##         the accuracy of the model and the model itself.
getModelAccuRankF <- function(xMN = NULL,
                              yFc = NULL,
                              methC = NULL,
                              methNamLs = list(x = "x",
                                  y = "y"),
                              methArgLs = NULL,
                              xTestMN = NULL,
                              yTestFc = NULL,
                              predNamLs = list(object = "object",
                                  newdata = "newdata"),
                              predArgLs = NULL){
  # removing constant variables
  varI <- ncol(xMN)
  varNamVc <- colnames(xMN)
  varCstVi <- which(apply(xMN, 2, var) <= .Machine["double.eps"])
  if(length(varCstVi) > 0)
    xMN <- xMN[, -varCstVi, drop = FALSE]

  model <- getModelF(xMN = xMN,
                     yFc = yFc,
                     methC = methC,
                     methNamLs = methNamLs,
                     methArgLs = methArgLs)

  if(length(varCstVi) > 0)
    xTestMN <- xTestMN[, -varCstVi, drop = FALSE]

  predTestFc <- getPredictionF(model = model,
                               xTestMN = xTestMN,
                               predNamLs = predNamLs,
                               predArgLs = predArgLs)
  ## accuracy
  accuracyN <- getAccuracyF(predTestFc = predTestFc,
                            yTestFc = yTestFc)

  ## feature importance

  varImpVn <- getImportanceF(model = model,
                             xTrainMN = xMN)
                             ## xTestMN = xTestMN,
                             ## yTestFc = yTestFc,
                             ## accuracyN = accuracyN,
                             ## predNamLs = predNamLs,
                             ## predArgLs = predArgLs)
  varImpFulVn <- rep(0, varI)
  if(length(varCstVi > 0))
    varImpFulVn[-varCstVi] <- varImpVn
  else
    varImpFulVn <- varImpVn
  ## generate the rank
  rankVn <- rank(-varImpFulVn, ties.method = "max")
  names(rankVn) <- varNamVc

  # generate the REM
  modelAccuRank <- list(rankVn = rankVn,
                        accuracyN = accuracyN,
                        model = model,
                        varImpVn = varImpFulVn,
                        varNamVc = varNamVc,
                        varCstVi = varCstVi)
  return(modelAccuRank)

} ## getModelAccuRankF


## INPUT: model: object containing a model (classifier)
##        xTestMN: numerical matrix corresponding to the test subset (row: observations, column: features)
##        predNamLs: list of arguments names for the input model and the input newdata of responses of the prediction method (object, newdata by default)
##        predArgLs: a list of arguments for the prediction "methC" (in addition to the object model and newdata)
## OUTPUT: factor of predictions
getPredictionF <- function(model = NULL,
                           xTestMN = NULL,
                           predNamLs = list(object = "object",
                               newdata = "newdata"),
                           predArgLs = NULL){

    ## generates the prediction
    ## generates the full arguments for the model prediction
    argNamFulVc <- c(predNamLs$object,
                     predNamLs$newdata,
                     names(predArgLs))
    ## generates the args list with the arg names just created
    argFulLs <- c(list(model,xTestMN),predArgLs)
    names(argFulLs) <- argNamFulVc

    ## generates the prediction
    predTestFc <- do.call(predict, argFulLs)

    return(predTestFc)

} ## getPredictionF




